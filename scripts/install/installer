#!/usr/bin/env python3
from js9 import j
import netaddr
import click
import itertools
import os
import sys
import time
import jsonschema

REPO_URL = 'https://github.com/0-complexity/openvcloud_installer'
REPO_PATH = '/opt/code/github/0-complexity/openvcloud_installer'
AYSCONFIG = '''
metadata.jumpscale             =
    branch:'{version}',
    url:'git@github.com:jumpscale7/ays_jumpscale7',

metadata.openvcloud            =
    branch:'{ovcversion}',
    url:'git@github.com:0-complexity/openvcloud_ays',
'''

WHOAMI = '''
email                          =

fullname                       =

git.login                      = 'ssh'
git.passwd                     = 'ssh'
'''

class JumpScale7:
    def __init__(self, prefab):
        self.prefab = prefab

    def install_core(self, version='master', ovcversion='master'):
        env = {'AYSBRANCH': version, 'JSBRANCH': version}
        cmd = 'cd /tmp;rm -f install.sh;curl -k https://raw.githubusercontent.com/jumpscale7/jumpscale_core7/{}/install/install.sh > install.sh;bash install.sh'.format(version)
        self.prefab.system.ssh.define_host('git.aydo.com')
        self.prefab.system.ssh.define_host('github.com')

        if self.prefab.bash.cmdGetPath('python', False) is False or self.prefab.bash.cmdGetPath('curl', False) is False:
            self.prefab.system.package.mdupdate()
            self.prefab.system.package.install('python')
            self.prefab.system.package.install('curl')
        if self.prefab.bash.cmdGetPath('js', False) is False:
            self.prefab.core.run(cmd, env=env)
        self.prefab.core.file_write('/opt/jumpscale7/hrd/system/atyourservice.hrd', AYSCONFIG.format(version=version, ovcversion=ovcversion))
        self.prefab.core.file_write('/opt/jumpscale7/hrd/system/whoami.hrd', WHOAMI)

    def install_agent(self, osishost, osispassword, achost, gid):
        redisdata = {
            'instance.param.disk': '0',
            'instance.param.mem': '100',
            'instance.param.passwd': '',
            'instance.param.port': '9999',
            'instance.param.ip' : '0.0.0.0',
            'instance.param.unixsocket': '0'
        }
        self.ays_install('redis', instance='system', data=redisdata)

        osisclientdata = {
            'param.osis.client.addr': osishost,
            'param.osis.client.login': 'root',
            'param.osis.client.passwd': osispassword,
            'param.osis.client.port': '5544',
        }
        self.ays_install('osis_client', instance='main', data=osisclientdata)
        self.ays_install('osis_client', instance='jsagent', data=osisclientdata)

        agentcontrollerdata = {
            'agentcontroller.client.addr': achost,
            'agentcontroller.client.login': 'node',
            'agentcontroller.client.passwd': '',
            'agentcontroller.client.port': '4444'
        }
        self.ays_install('agentcontroller_client', instance='main', data=agentcontrollerdata)

        agentdata = {
                'agentcontroller.connection': 'main',
                'grid.id': str(gid),
                'grid.node.roles': 'node',
                'osis.connection': 'jsagent',
        }
        self.ays_install('jsagent', instance='main', data=agentdata)


    def ays_install(self, package, domain='jumpscale', instance='main', data=None):
        datastr = ''
        data = data or {}
        for key, value in data.items():
            datastr += "{}:{} ".format(key, value)
        cmd = 'ays install -d {} -n {} -i {} --data "{}"'.format(domain, package, instance, datastr)
        self.prefab.core.run(cmd)

    def install_compute_node(self, netinfo, fqdn, masterhost, masterpassword, gid):
        data_net = {
            'netconfig.public_backplane.interfacename': 'backplane1',
            'netconfig.gw_mgmt_backplane.interfacename': 'backplane1',
            'netconfig.vxbackend.interfacename': 'backplane1',
            'netconfig.gw_mgmt.vlanid': netinfo['gwmgmt_vlan'],
            'netconfig.vxbackend.vlanid': netinfo['vxbackend_vlan'],
            'netconfig.gw_mgmt.ipaddr': netinfo['gwmgmt_ip'],
            'netconfig.vxbackend.ipaddr': netinfo['vxbackend_ip'],
        }

        data_cpu = {
            'param.rootpasswd': '',
            'param.master.addr': '',
            'param.network.gw_mgmt_ip': netinfo['gwmgmt_ip'],
            'param.grid.id': gid,
        }

        portal_client = {
            'param.addr' : fqdn,
            'param.port': '443',
            'param.secret': masterpassword,
        }

        print('Install portal client')
        self.ays_install('portal_client', domain='jumpscale', instance='main', data=portal_client)


        print('installing network')
        self.ays_install('scaleout_networkconfig', domain='openvcloud', instance='main', data=data_net)

        print('installing cpu node')
        self.ays_install('cb_cpunode_aio', domain='openvcloud', instance='main', data=data_cpu)



    def install_storage_node(self, masterhost, masterpassword, gid, driver=False, alba=False):

        data_storage = {
            'instance.param.rootpasswd': masterpassword,
            'instance.param.master.addr': masterhost,
            'instance.param.grid.id': gid,
        }

        print('[+] installing storage node')
        self.ays_install('cb_storagenode_aio', domain='openvcloud', instance='main', data=data_storage)
        if driver:
            self.ays_install('cb_storagedriver_aio', domain='openvcloud', instance='main', data=data_storage)
            if 'MASTER' in self.prefab.core.run('ovs config get "ovs/framework/hosts/$(cat /etc/openvstorage_id)/type"'):
                if alba:
                    self.prefab.core.run("python /opt/code/github/0-complexity/openvcloud/scripts/ovs/alba-create-user.py")
                # TODO (on halt for now)
                # loading ovc_master oauth server keys
                # oauthfile = '/tmp/oauthserver.hrd'
                # ovc_iyo = j.atyourservice.get(name='ovc_itsyouonline')
                # ovc_iyo.actions.prepare(ovc_iyo)
                # environment = settings.get('instance.ovc.environment')
                # location = node.parent.instance
                # apikeyname = 'ovs-{}-{}'.format(environment, location)
                # domain = configure.get('instance.param.domain')
                # ovscallbackurl = 'https://ovs-{}.{}/api/oauth2/redirect/'.format(location, domain)
                # apikey = {'callbackURL': ovscallbackurl,
                #         'clientCredentialsGrantType': False,
                #         'label': apikeyname
                #         }
                # apikey = ovc_iyo.actions.configure_api_key(apikey)

                # j.console.info('building oauth configuration')
                # oauth_token_uri = os.path.join(ovc_iyo.actions.baseurl, 'v1/oauth/access_token')
                # oauth_authorize_uri = os.path.join(ovc_iyo.actions.baseurl, 'v1/oauth/authorize')

                # data_oauth = {'instance.oauth.id': ovc_iyo.actions.client_id,
                #             'instance.oauth.secret': apikey['secret'],
                #             'instance.oauth.authorize_uri': oauth_authorize_uri,
                #             'instance.oauth.token_uri': oauth_token_uri}

                # temp = j.atyourservice.new(name='openvstorage_oauth', instance='main', args=data_oauth, parent=node)
                # temp.consume('node', node.instance)
                # temp.install(deps=True)

def get_ipaddress(net):
    return str(netaddr.IPNetwork(net).ip)

def prepare_config(config_path):
    def _helper(nodes):
        for node in nodes:
            net = netaddr.IPNetwork(value['network'])
            ip = net.ip + node['ip-lsb']
            if key not in node:
                node[key] = {}
            node[key]['ipaddress'] = '{ip}/{sub}'.format(ip=ip, sub=net.prefixlen)

    config = j.data.serializer.yaml.load(config_path)
    validator = j.data.serializer.json.load('{}/scripts/kubernetes/config/config-validator.json'.format(REPO_PATH))
    try:
        jsonschema.validate(config, validator)
    except Exception as error:
        message = getattr(error, "message", str(type(error)))
        tree = ''
        for seq in getattr(error, "path", list()):
            if isinstance(seq, int):
                tree += '/<sequence {}>'.format(seq)
            else:
                tree += "/{}".format(seq)

        validator = getattr(error, "validator")
        if  validator == 'type':
            message = '{msg} at {tree}'.format(msg=message, tree=tree)
        elif validator == 'required':
            message = "{msg} in config at {tree}. Please check example config for reference.".format(msg=message, tree=tree)
        raise j.exceptions.RuntimeError(message)

    for key, value in config['network'].items():
        if 'network' in value:
            for nodes in config['nodes'].values():
                _helper(nodes)
            _helper(config['controller']['hosts'])
    return config

def get_controller_management_ips(config):
    for host in config['controller']['hosts']:
        yield get_ipaddress(host['management']['ipaddress'])

def get_controller_public_ips(config):
    for host in config['controller']['hosts']:
        yield get_ipaddress(host['fallback']['ipaddress'])

class AbstractConfig:
    def __init__(self, config):
        self.config = config
        self.prefab = j.tools.prefab.local
        self._nodes = None

    @property
    def nodes(self):
        if self._nodes is None:
            nodes = []
            j.clients.ssh.start_ssh_agent()
            key = self.config['ssh']['private-key']
            self.prefab.core.run('echo "%s" | ssh-add /dev/stdin' % key)
            for address in get_controller_public_ips(self.config):
                executor = j.tools.executor.getSSHBased(address, usecache=False)
                nodes.append(j.tools.prefab.get(executor))
            self._nodes = nodes
        return self._nodes

    @property
    def first_node(self):
        return self.nodes[0]

    def kubectl(self, *args):
        cmd = "kubectl "
        cmd += " ".join(args)
        return self.first_node.core.run(cmd)

    def get_node_from_appname(self, appname):
        status, output, _ = self.kubectl("get pods -o json")
        data = j.data.serializer.json.loads(output)
        for pod in data['items']:
            if pod['metadata']['labels'].get('app') != appname:
                continue
            hostip = pod['status']['hostIP']
            for node in self.nodes:
                netinfo = node.system.net.getInfo()
                for nic in netinfo:
                    for ip in nic['ip']:
                        if ip == hostip:
                            return node

            raise LookupError("Could not find host with IP {}".format(hostip))
        raise LookupError("Could not find appname {}".appname)


class Cluster(AbstractConfig):
    """
    Cluster abstraction layer to allow for easier manipulation.
    """
    def __init__(self, config_path):
        super().__init__(config_path)
        self.k8s_config = '/root/.kube/{}.conf'.format(self.config['environment']['subdomain'])
        self.join_line = ''

    def install_kubernetes_cluster(self):
        """
        Will install a kubernetes master and minion nodes on the first and rest of the node list respectively.
        """
        for node in self.nodes:
            node.core.run('swapoff -a')

        managementips = list(get_controller_management_ips(self.config))
        k8s_config_data, self.join_line = self.prefab.virtualization.kubernetes.multihost_install(
                self.nodes, unsafe=True, reset=True, external_ips=managementips)
        self.prefab.core.dir_ensure('/root/.kube')
        self.prefab.core.file_write(self.k8s_config, k8s_config_data)
        if not self.prefab.core.file_exists('/root/.kube/config'):
            self.prefab.core.file_write('/root/.kube/config', k8s_config_data)

    def clone_repo(self):
        for node in self.nodes:
            node.tools.git.pullRepo(REPO_URL)

    def _install_kubectl(self, prefab):
        if not prefab.core.file_exists('/usr/local/bin/kubectl'):
            prefab.virtualization.kubernetes.install_kube_client(location='/usr/local/bin/kubectl')


    def install_controller(self):
        """
        Will use existing yaml or config scripts in this dir as well as jumpscale modules to install the controller setup on the
        cluster. Creating the relevant deployments, services, and mounts
        TODO
        """

        for node in self.nodes:
            self._install_kubectl(node)
        self._install_kubectl(self.prefab)
        self.clone_repo()

        directories = self.config['controller'].get('directories')
        for node in self.nodes:
            for directory in directories:
                node.core.dir_ensure(directory, mode='777')

        copiedpaths = {}
        try:
            for key, value in self.config['environment']['ssl'].items():
                path = os.path.join(value['path'], '')
                if path not in copiedpaths:
                    tmpdir = self.first_node.core.file_get_tmp_path()
                    # make sure tmpdir has trailing slash
                    tmpdir = os.path.join(tmpdir, '')
                    self.first_node.core.dir_ensure(tmpdir)
                    self.first_node.core.upload(path, tmpdir)
                    copiedpaths[path] = tmpdir
                else:
                    tmpdir = copiedpaths[path]
                self.kubectl('create secret generic {name}-certs --from-file {dir}'.format(name=key, dir=tmpdir))
        finally:
            for tmpdir in copiedpaths.values():
                self.first_node.core.dir_remove(tmpdir)

        self.kub_client_apply()

    # Not ready yet do not use
    def _apply_deploy(self, template):
        self.kubectl('apply -f {template}'.format(template=template))
        template_name = j.sal.fs.getBaseName(template)
        timeout = time.time() + 240
        print('Waiting for deployment %s to be ready..' % template_name)
        while time.time() < timeout:
            _, out, _ = self.kubectl('get deploy -o json')
            ready = False
            for item in out['items']:
                if item['metadata']['name'] == template_name:
                    if item['status'].get('readyReplicas') and item['status']['readyReplicas'] == item['state']['replicas']:
                        ready = True
                        break
            if ready:
                break
        else:
            raise j.exceptions.Timeout('Deploying %s took longer than expected. Exiting..')

    def dump(self, location, data, dumper=j.data.serializer.yaml.dumps):
        data = dumper(data)
        self.first_node.core.file_write(location, data)

    def load(self, location, loader=j.data.serializer.yaml.loads):
        data = self.first_node.core.file_read(location)
        return loader(data)

    def _prepare_templates(self, scripts_dir):
        def write_template(template, externalips):
            template_loc = '{dir}{name}/{name}-service.yaml'.format(dir=scripts_dir, name=template)
            data = self.load(template_loc)
            data['spec']['externalIPs'] = externalips
            self.dump(template_loc, data)

        templates = ['agentcontroller', 'osis', '0-access']
        externalips = [node.executor.sshclient.addr for node in self.nodes]
        for template in templates:
            write_template(template, externalips)
        write_template('nginx', list(get_controller_public_ips(self.config)))

        stat_template = scripts_dir + '/stats-collector/stats-deployment.yaml'
        data = self.load(stat_template)
        data['spec']['template']['spec']['containers'][0]['args'][4] = self.config['network']['management']['network']
        self.dump(stat_template, data)

    def write_system_config(self):
        tmpdir = self.first_node.core.file_get_tmp_path()
        self.first_node.core.dir_ensure(tmpdir)
        tmpfile = j.sal.fs.joinPaths(tmpdir, 'system-config.yaml')
        try:
            self.dump(tmpfile, self.config)
            self.kubectl('create configmap system-config --from-file {path}'.format(
                            path=tmpfile))
        finally:
            self.first_node.core.dir_remove(tmpdir)

    def kub_client_apply(self, scripts_dir='{}/templates/'):
        scripts_dir = scripts_dir.format(REPO_PATH)
        self.first_node.core.copyTree('{}/scripts/kubernetes'.format(REPO_PATH), scripts_dir)
        self._prepare_templates(scripts_dir)
        self.write_system_config()

        self.kubectl('apply -f {path}/rbac.yaml'.format(path=scripts_dir))
        templates = ['syncthing', 'mongocluster', 'influxdb', 'osis', 'agentcontroller', 'stats-collector', 'portal', 'nginx', 'pxeboot', '0-access', 'management']
        for template in templates:
            template_file = scripts_dir + template
            self.kubectl('apply -f {template}'.format(template=template_file))
        self.grafana_apply('{}/grafana'.format(scripts_dir))

    def grafana_apply(self, grafana_dir):
        datasourcepath = '{}/provisioning/datasources/influx.yaml'.format(grafana_dir)
        dashboardpath = '{}/sources/templates'.format(grafana_dir)
        datasource = self.load(datasourcepath)
        datasourcename = 'controller_{}'.format(self.config['environment']['subdomain'])
        datasource['datasources'][0]['name'] = datasourcename
        self.dump(datasourcepath, datasource)
        for dashboardfile in j.sal.fs.listFilesInDir(dashboardpath, filter='*.json'):
            db = self.load(dashboardfile, j.data.serializer.json.loads)
            db['id'] = None
            db['title'] += " ({})".format(self.config['environment']['subdomain'])
            for row in db['rows']:
                for panel in row['panels']:
                    panel['datasource'] = datasourcename
            if 'templating' in db:
                for item in db['templating']['list']:
                    item['datasource'] = datasourcename
            self.dump(dashboardfile, db, j.data.serializer.json.dumps)
        cmd = """
        cd {dir}
        kubectl create configmap grafana-provisioning-datasources --from-file=provisioning/datasources
        kubectl create configmap grafana-provisioning-dashboards --from-file=provisioning/dashboards
        kubectl create configmap grafana-dashboards --from-file=sources/templates
        kubectl apply -f grafana-service.yaml
        kubectl apply -f grafana-deployment.yaml
        """.format(config=self.k8s_config, dir=grafana_dir)
        self.first_node.core.execute_bash(cmd)


class PNode(AbstractConfig):
    def __init__(self, config, name):
        super().__init__(config)
        self._node = None
        self.name = name
        self.managementip = get_ipaddress(self.node['management']['ipaddress'])

    @property
    def node(self):
        if self._node is None:
            for node in itertools.chain(self.config['nodes']['cpu'], self.config['nodes']['storage']):
                if node['name'] == self.name:
                    self._node = node
                    return node
            raise LookupError("Failed to find node with name {}".format(self.name))
        return self._node

    def ipmi(self, *args):
        ipmiip = get_ipaddress(self.node['ipmi']['ipaddress'])
        cmd = "ipmitool -I lanplus -H {} -U {} -P {} ".format(ipmiip, self.node['ipmi']['username'], self.node['ipmi']['password'])
        cmd += " ".join(args)
        self.first_node.core.run(cmd)

    def reboot(self):
        self.ipmi('chassis power cycle')

    def is_up(self):
        return j.sal.nettools.tcpPortConnectionTest(self.managementip, 22)

    def wait_up(self, timeout=300):
        j.sal.nettools.waitConnectionTest(self.managementip, 22, timeout)
        if not self.is_up():
            raise RuntimeError('Node did not come up in {}seconds'.format(timeout))

    def enable_pxe(self):
        prefab = self.get_node_from_appname('pxeboot')
        self.ipmi('chassis bootdev pxe')
        macaddress = str(netaddr.EUI(self.node['management']['macaddress'])).lower()
        dst = '/var/ovc/pxeboot/tftpboot/pxelinux.cfg/01-{}'.format(macaddress)
        src = '../../conf/tftp-911boot'
        prefab.core.file_link(src, dst)

    def disable_pxe(self):
        prefab = self.get_node_from_appname('pxeboot')
        macaddress = str(netaddr.EUI(self.node['management']['macaddress'])).lower()
        dst = '/var/ovc/pxeboot/tftpboot/pxelinux.cfg/01-{}'.format(macaddress)
        prefab.core.file_remove(dst)

    def install_os(self):
        self.enable_pxe()
        self.reboot()
        time.sleep(20)
        self.wait_up()
        prefab = j.tools.prefab.getFromSSH(self.managementip)
        status, output, err = prefab.core.run('/root/tools/Install')
        if status != 0:
            raise RuntimeError('Failed to install OS')
        self.disable_pxe()
        self.reboot()
        time.sleep(20)
        self.wait_up()


###                    ###
# Command line interface #
###                    ###

@click.group()
@click.option('--config', help='Config file to deploy the cluster', envvar='ENV_CONFIG')
@click.pass_context
def cli(ctx, config):
    if not config:
        raise j.exceptions.Input('Please specify a config file')
    config = prepare_config(config)
    ctx.obj = config

@cli.group()
def cluster():
    pass

@cli.group()
def node():
    pass

@cli.group()
def cpu():
    pass

@cli.group()
def storage():
    pass


@node.command('action')
@click.option('--name', help='Node name')
@click.argument('action')
@click.pass_context
def node_action(ctx, name, action):
    """
    Execute command for node
    """
    cluster = PNode(ctx.obj, name)
    getattr(cluster, action)()


@cluster.command('writeconfig')
@click.pass_context
def write_system_config(ctx):
    """
    Write or update system-config in kubernetes configmap based on yaml file
    """
    cluster = Cluster(ctx.obj)
    cluster.write_system_config()


@cluster.command('deploy')
@click.option('--configure-cluster/--no-configure-cluster', help='Configure kubernetes cluster', default=True)
@click.pass_context
def deploy_cluster(ctx, configure_cluster):
    """
    Deploy will create the cluster machines and deploy kubernetes cluster on top of them.
    """
    cluster = Cluster(ctx.obj)
    if configure_cluster:
        cluster.install_kubernetes_cluster()
    cluster.install_controller()



@cpu.command('deploy')
@click.option('--node-name', help='Node name to configure')
@click.pass_context
def deploy_cpu(ctx, node_name):
    config = ctx.obj
    for cpunode in config['nodes']['cpu']:
        if cpunode['name'] == node_name:
            break
    else:
        print('Could not find node with name {}'.format(node_name))
        sys.exit(1)

    ip = get_ipaddress(cpunode['management']['ipaddress'])
    prefab = j.tools.prefab.getFromSSH(ip)
    jumpscale = JumpScale7(prefab)
    versions = config['environment']['versions']
    password = config['environment']['password']
    gid = config['environment']['grid']['id']
    jumpscale.install_core(versions['jumpscale'], versions['openvcloud'])
    controllerips = []
    for address in get_controller_management_ips(config):
        controllerips.append(address)

    hostips = ','.join(controllerips)
    jumpscale.install_agent(hostips, password, hostips, gid)
    netinfo = {
        'vxbackend_vlan': config['network']['vxbackend']['vlan'],
        'vxbackend_ip': cpunode['vxbackend']['ipaddress'],
        'gwmgmt_vlan': config['network']['gateway-management']['vlan'],
        'gwmgmt_ip': cpunode['gateway-management']['ipaddress'],

    }
    fqdn = '{}.{}'.format(config['environment']['subdomain'], config['environment']['basedomain'])
    jumpscale.install_compute_node(netinfo, fqdn, hostips, password, gid)


@storage.command('deploy')
@click.option('--node-name', help='Node name to configure')
@click.pass_context
def deploy_storage(ctx, node_name):
    config = ctx.obj
    for storage_node in config['nodes']['storage']:
        if storage_node['name'] == node_name:
            break
    else:
        print('Could not find node with name {}'.format(node_name))
        sys.exit(1)

    ip = get_ipaddress(storage_node['management']['ipaddress'])
    prefab = j.tools.prefab.getFromSSH(ip)
    jumpscale = JumpScale7(prefab)
    versions = config['environment']['versions']
    password = config['environment']['password']
    gid = config['environment']['grid']['id']
    jumpscale.install_core(versions['jumpscale'], versions['openvcloud'])
    controllerips = []
    for address in get_controller_management_ips(config):
        controllerips.append(address)

    hostips = ','.join(controllerips)
    jumpscale.install_agent(hostips, password, hostips, gid)
    jumpscale.install_storage_node(hostips, password, gid, driver=True, alba=False)


def build_images():
    """
    build the releveant images that will be used to run the deployments
    TODO
    """


if __name__ == '__main__':
    cli()


